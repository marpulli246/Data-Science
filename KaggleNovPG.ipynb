{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleNovPG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNZZTAv1sfs93Gcr4KM5pzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marpulli246/Kaggle/blob/main/KaggleNovPG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cytz_-n2s9Ci",
        "outputId": "1ab97d64-0835-4340-c61b-c0ef2a28eea1"
      },
      "source": [
        "pip install scikeras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.6.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging<22.0,>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.1)\n",
            "Collecting importlib-metadata<4,>=3\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4,>=3->scikeras) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4,>=3->scikeras) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<22.0,>=0.21->scikeras) (3.0.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.19.5)\n",
            "Installing collected packages: importlib-metadata, scikeras\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.2\n",
            "    Uninstalling importlib-metadata-4.8.2:\n",
            "      Successfully uninstalled importlib-metadata-4.8.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed importlib-metadata-3.10.1 scikeras-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTSyXKCMEuF9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import datasets, metrics, model_selection, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell #enables multiple cell outputs withput print command.\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWX6FSPUExgl",
        "outputId": "e6c239e9-45ba-4600-8781-5fd458ddc065"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02ejPQieFKYq"
      },
      "source": [
        "train =  pd.read_csv('/content/drive/MyDrive/Kaggle_Nov/train.csv.gz')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Kaggle_Nov/test.csv.gz')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "0-oZNKd-NqQ6",
        "outputId": "9e5f5b75-0a85-4394-b10f-0e51b2d34a4b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>f0</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>...</th>\n",
              "      <th>f61</th>\n",
              "      <th>f62</th>\n",
              "      <th>f63</th>\n",
              "      <th>f64</th>\n",
              "      <th>f65</th>\n",
              "      <th>f66</th>\n",
              "      <th>f67</th>\n",
              "      <th>f68</th>\n",
              "      <th>f69</th>\n",
              "      <th>f70</th>\n",
              "      <th>f71</th>\n",
              "      <th>f72</th>\n",
              "      <th>f73</th>\n",
              "      <th>f74</th>\n",
              "      <th>f75</th>\n",
              "      <th>f76</th>\n",
              "      <th>f77</th>\n",
              "      <th>f78</th>\n",
              "      <th>f79</th>\n",
              "      <th>f80</th>\n",
              "      <th>f81</th>\n",
              "      <th>f82</th>\n",
              "      <th>f83</th>\n",
              "      <th>f84</th>\n",
              "      <th>f85</th>\n",
              "      <th>f86</th>\n",
              "      <th>f87</th>\n",
              "      <th>f88</th>\n",
              "      <th>f89</th>\n",
              "      <th>f90</th>\n",
              "      <th>f91</th>\n",
              "      <th>f92</th>\n",
              "      <th>f93</th>\n",
              "      <th>f94</th>\n",
              "      <th>f95</th>\n",
              "      <th>f96</th>\n",
              "      <th>f97</th>\n",
              "      <th>f98</th>\n",
              "      <th>f99</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.106643</td>\n",
              "      <td>3.59437</td>\n",
              "      <td>132.8040</td>\n",
              "      <td>3.18428</td>\n",
              "      <td>0.081971</td>\n",
              "      <td>1.18859</td>\n",
              "      <td>3.73238</td>\n",
              "      <td>2.266270</td>\n",
              "      <td>2.09959</td>\n",
              "      <td>0.012330</td>\n",
              "      <td>1.607190</td>\n",
              "      <td>-0.318058</td>\n",
              "      <td>0.560137</td>\n",
              "      <td>2.806880</td>\n",
              "      <td>1.35114</td>\n",
              "      <td>2.535930</td>\n",
              "      <td>0.197527</td>\n",
              "      <td>0.676494</td>\n",
              "      <td>1.98979</td>\n",
              "      <td>-3.842450</td>\n",
              "      <td>0.037380</td>\n",
              "      <td>0.230322</td>\n",
              "      <td>3.33055</td>\n",
              "      <td>0.009397</td>\n",
              "      <td>0.144738</td>\n",
              "      <td>3.05131</td>\n",
              "      <td>1.30362</td>\n",
              "      <td>0.033225</td>\n",
              "      <td>-0.018284</td>\n",
              "      <td>2.748210</td>\n",
              "      <td>-0.009294</td>\n",
              "      <td>-0.036271</td>\n",
              "      <td>-0.049871</td>\n",
              "      <td>0.019484</td>\n",
              "      <td>3.898460</td>\n",
              "      <td>11.2863</td>\n",
              "      <td>1.138020</td>\n",
              "      <td>3.366880</td>\n",
              "      <td>4.94446</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027551</td>\n",
              "      <td>0.019483</td>\n",
              "      <td>-0.048826</td>\n",
              "      <td>0.050748</td>\n",
              "      <td>3.729300</td>\n",
              "      <td>5.017440</td>\n",
              "      <td>4.186880</td>\n",
              "      <td>0.063342</td>\n",
              "      <td>0.121043</td>\n",
              "      <td>1.37175</td>\n",
              "      <td>4.017450</td>\n",
              "      <td>0.167613</td>\n",
              "      <td>0.039753</td>\n",
              "      <td>2.042360</td>\n",
              "      <td>-0.016614</td>\n",
              "      <td>0.107679</td>\n",
              "      <td>3.507250</td>\n",
              "      <td>0.013660</td>\n",
              "      <td>-0.097023</td>\n",
              "      <td>5.396070</td>\n",
              "      <td>0.244457</td>\n",
              "      <td>3.49184</td>\n",
              "      <td>0.113090</td>\n",
              "      <td>-0.015472</td>\n",
              "      <td>4.208790</td>\n",
              "      <td>4.106560</td>\n",
              "      <td>0.037227</td>\n",
              "      <td>-0.118814</td>\n",
              "      <td>0.067086</td>\n",
              "      <td>0.010739</td>\n",
              "      <td>1.09862</td>\n",
              "      <td>0.013331</td>\n",
              "      <td>-0.011715</td>\n",
              "      <td>0.052759</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>4.211250</td>\n",
              "      <td>1.97877</td>\n",
              "      <td>0.085974</td>\n",
              "      <td>0.240496</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.125021</td>\n",
              "      <td>1.67336</td>\n",
              "      <td>76.5336</td>\n",
              "      <td>3.37825</td>\n",
              "      <td>0.099400</td>\n",
              "      <td>5.09366</td>\n",
              "      <td>1.27562</td>\n",
              "      <td>-0.471318</td>\n",
              "      <td>4.54594</td>\n",
              "      <td>0.037706</td>\n",
              "      <td>0.331749</td>\n",
              "      <td>0.325091</td>\n",
              "      <td>0.062040</td>\n",
              "      <td>2.262150</td>\n",
              "      <td>4.33943</td>\n",
              "      <td>-0.224999</td>\n",
              "      <td>0.233586</td>\n",
              "      <td>3.381280</td>\n",
              "      <td>1.90299</td>\n",
              "      <td>0.067874</td>\n",
              "      <td>-0.051268</td>\n",
              "      <td>0.006135</td>\n",
              "      <td>2.60444</td>\n",
              "      <td>0.103441</td>\n",
              "      <td>0.067638</td>\n",
              "      <td>4.75362</td>\n",
              "      <td>1.85552</td>\n",
              "      <td>-0.181834</td>\n",
              "      <td>0.008359</td>\n",
              "      <td>3.166340</td>\n",
              "      <td>0.011850</td>\n",
              "      <td>0.022292</td>\n",
              "      <td>0.069320</td>\n",
              "      <td>0.117109</td>\n",
              "      <td>0.315276</td>\n",
              "      <td>24.4807</td>\n",
              "      <td>1.672270</td>\n",
              "      <td>-0.409067</td>\n",
              "      <td>4.95475</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010841</td>\n",
              "      <td>0.064584</td>\n",
              "      <td>0.102548</td>\n",
              "      <td>0.093611</td>\n",
              "      <td>0.964089</td>\n",
              "      <td>0.630422</td>\n",
              "      <td>4.307340</td>\n",
              "      <td>0.091289</td>\n",
              "      <td>-0.036360</td>\n",
              "      <td>3.61767</td>\n",
              "      <td>3.103240</td>\n",
              "      <td>0.000657</td>\n",
              "      <td>0.051302</td>\n",
              "      <td>1.924620</td>\n",
              "      <td>0.123294</td>\n",
              "      <td>-0.022671</td>\n",
              "      <td>1.548120</td>\n",
              "      <td>-0.010397</td>\n",
              "      <td>0.058330</td>\n",
              "      <td>3.661310</td>\n",
              "      <td>-0.118386</td>\n",
              "      <td>2.35739</td>\n",
              "      <td>-0.009112</td>\n",
              "      <td>0.178701</td>\n",
              "      <td>4.097350</td>\n",
              "      <td>3.532890</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>0.121381</td>\n",
              "      <td>0.109968</td>\n",
              "      <td>0.135838</td>\n",
              "      <td>3.46017</td>\n",
              "      <td>0.017054</td>\n",
              "      <td>0.124863</td>\n",
              "      <td>0.154064</td>\n",
              "      <td>0.606848</td>\n",
              "      <td>-0.267928</td>\n",
              "      <td>2.57786</td>\n",
              "      <td>-0.020877</td>\n",
              "      <td>0.024719</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.036330</td>\n",
              "      <td>1.49747</td>\n",
              "      <td>233.5460</td>\n",
              "      <td>2.19435</td>\n",
              "      <td>0.026914</td>\n",
              "      <td>3.12694</td>\n",
              "      <td>5.05687</td>\n",
              "      <td>3.849460</td>\n",
              "      <td>1.80187</td>\n",
              "      <td>0.056995</td>\n",
              "      <td>0.328684</td>\n",
              "      <td>2.968810</td>\n",
              "      <td>0.105244</td>\n",
              "      <td>2.069490</td>\n",
              "      <td>5.30986</td>\n",
              "      <td>1.354790</td>\n",
              "      <td>-0.262018</td>\n",
              "      <td>1.379080</td>\n",
              "      <td>1.48091</td>\n",
              "      <td>0.020542</td>\n",
              "      <td>-0.008806</td>\n",
              "      <td>0.109348</td>\n",
              "      <td>1.68365</td>\n",
              "      <td>0.038180</td>\n",
              "      <td>0.123716</td>\n",
              "      <td>1.11248</td>\n",
              "      <td>3.57166</td>\n",
              "      <td>0.120601</td>\n",
              "      <td>0.082069</td>\n",
              "      <td>2.233520</td>\n",
              "      <td>0.002270</td>\n",
              "      <td>0.045182</td>\n",
              "      <td>0.014405</td>\n",
              "      <td>0.011599</td>\n",
              "      <td>-0.502849</td>\n",
              "      <td>33.7382</td>\n",
              "      <td>1.417500</td>\n",
              "      <td>1.071350</td>\n",
              "      <td>3.22296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027571</td>\n",
              "      <td>-0.007121</td>\n",
              "      <td>-0.048914</td>\n",
              "      <td>-0.002574</td>\n",
              "      <td>1.865090</td>\n",
              "      <td>2.404170</td>\n",
              "      <td>0.411741</td>\n",
              "      <td>0.057749</td>\n",
              "      <td>0.525174</td>\n",
              "      <td>2.16879</td>\n",
              "      <td>0.828297</td>\n",
              "      <td>0.089848</td>\n",
              "      <td>0.093744</td>\n",
              "      <td>4.949010</td>\n",
              "      <td>-0.010978</td>\n",
              "      <td>0.076671</td>\n",
              "      <td>0.266784</td>\n",
              "      <td>0.038691</td>\n",
              "      <td>0.382731</td>\n",
              "      <td>3.847600</td>\n",
              "      <td>-0.121482</td>\n",
              "      <td>3.74084</td>\n",
              "      <td>0.147098</td>\n",
              "      <td>-0.016566</td>\n",
              "      <td>0.614651</td>\n",
              "      <td>2.125840</td>\n",
              "      <td>0.078828</td>\n",
              "      <td>0.979808</td>\n",
              "      <td>0.026758</td>\n",
              "      <td>0.117310</td>\n",
              "      <td>4.88300</td>\n",
              "      <td>0.085222</td>\n",
              "      <td>0.032396</td>\n",
              "      <td>0.116092</td>\n",
              "      <td>-0.001688</td>\n",
              "      <td>-0.520069</td>\n",
              "      <td>2.14112</td>\n",
              "      <td>0.124464</td>\n",
              "      <td>0.148209</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.014077</td>\n",
              "      <td>0.24600</td>\n",
              "      <td>779.9670</td>\n",
              "      <td>1.89064</td>\n",
              "      <td>0.006948</td>\n",
              "      <td>1.53112</td>\n",
              "      <td>2.69800</td>\n",
              "      <td>4.517330</td>\n",
              "      <td>4.50332</td>\n",
              "      <td>0.123494</td>\n",
              "      <td>1.002680</td>\n",
              "      <td>4.869600</td>\n",
              "      <td>0.058411</td>\n",
              "      <td>2.497850</td>\n",
              "      <td>1.23843</td>\n",
              "      <td>2.348360</td>\n",
              "      <td>0.175475</td>\n",
              "      <td>1.608890</td>\n",
              "      <td>2.02881</td>\n",
              "      <td>0.042086</td>\n",
              "      <td>0.005141</td>\n",
              "      <td>0.076506</td>\n",
              "      <td>1.65122</td>\n",
              "      <td>0.111813</td>\n",
              "      <td>0.121641</td>\n",
              "      <td>0.58912</td>\n",
              "      <td>4.23692</td>\n",
              "      <td>-0.032843</td>\n",
              "      <td>0.058168</td>\n",
              "      <td>0.712927</td>\n",
              "      <td>0.097465</td>\n",
              "      <td>0.072744</td>\n",
              "      <td>0.000324</td>\n",
              "      <td>0.063362</td>\n",
              "      <td>4.063820</td>\n",
              "      <td>25.3824</td>\n",
              "      <td>0.576572</td>\n",
              "      <td>2.026210</td>\n",
              "      <td>2.96843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.110884</td>\n",
              "      <td>0.026837</td>\n",
              "      <td>2.931160</td>\n",
              "      <td>0.068112</td>\n",
              "      <td>-0.495192</td>\n",
              "      <td>1.345280</td>\n",
              "      <td>2.242750</td>\n",
              "      <td>0.035611</td>\n",
              "      <td>-0.139274</td>\n",
              "      <td>4.74243</td>\n",
              "      <td>3.292740</td>\n",
              "      <td>0.117877</td>\n",
              "      <td>0.065605</td>\n",
              "      <td>0.556711</td>\n",
              "      <td>-0.058029</td>\n",
              "      <td>0.070501</td>\n",
              "      <td>1.101250</td>\n",
              "      <td>0.068559</td>\n",
              "      <td>0.162928</td>\n",
              "      <td>4.070180</td>\n",
              "      <td>-0.008835</td>\n",
              "      <td>3.89678</td>\n",
              "      <td>0.913739</td>\n",
              "      <td>-0.163204</td>\n",
              "      <td>3.074850</td>\n",
              "      <td>4.356780</td>\n",
              "      <td>-0.048894</td>\n",
              "      <td>4.917990</td>\n",
              "      <td>0.069930</td>\n",
              "      <td>-0.015347</td>\n",
              "      <td>3.47439</td>\n",
              "      <td>-0.017103</td>\n",
              "      <td>-0.008100</td>\n",
              "      <td>0.062013</td>\n",
              "      <td>0.041193</td>\n",
              "      <td>0.511657</td>\n",
              "      <td>1.96860</td>\n",
              "      <td>0.040017</td>\n",
              "      <td>0.044873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>-0.003259</td>\n",
              "      <td>3.71542</td>\n",
              "      <td>156.1280</td>\n",
              "      <td>2.14772</td>\n",
              "      <td>0.018284</td>\n",
              "      <td>2.09859</td>\n",
              "      <td>4.15492</td>\n",
              "      <td>-0.038236</td>\n",
              "      <td>3.37145</td>\n",
              "      <td>0.034166</td>\n",
              "      <td>0.711483</td>\n",
              "      <td>0.769988</td>\n",
              "      <td>0.057555</td>\n",
              "      <td>0.957257</td>\n",
              "      <td>3.71145</td>\n",
              "      <td>5.464350</td>\n",
              "      <td>0.287104</td>\n",
              "      <td>2.616950</td>\n",
              "      <td>1.38403</td>\n",
              "      <td>0.074883</td>\n",
              "      <td>-0.010543</td>\n",
              "      <td>0.109121</td>\n",
              "      <td>2.27602</td>\n",
              "      <td>0.008023</td>\n",
              "      <td>0.045235</td>\n",
              "      <td>4.35954</td>\n",
              "      <td>5.07562</td>\n",
              "      <td>-0.009376</td>\n",
              "      <td>0.528966</td>\n",
              "      <td>4.053350</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.106828</td>\n",
              "      <td>0.051307</td>\n",
              "      <td>0.045939</td>\n",
              "      <td>3.402460</td>\n",
              "      <td>15.5615</td>\n",
              "      <td>1.635960</td>\n",
              "      <td>0.047029</td>\n",
              "      <td>4.01771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075586</td>\n",
              "      <td>0.032114</td>\n",
              "      <td>-0.042284</td>\n",
              "      <td>0.047974</td>\n",
              "      <td>-0.294184</td>\n",
              "      <td>5.065600</td>\n",
              "      <td>1.050290</td>\n",
              "      <td>0.034019</td>\n",
              "      <td>0.024611</td>\n",
              "      <td>3.12578</td>\n",
              "      <td>2.262840</td>\n",
              "      <td>0.082462</td>\n",
              "      <td>-0.023296</td>\n",
              "      <td>5.615850</td>\n",
              "      <td>0.086238</td>\n",
              "      <td>0.157568</td>\n",
              "      <td>3.725670</td>\n",
              "      <td>0.061247</td>\n",
              "      <td>0.086603</td>\n",
              "      <td>0.607246</td>\n",
              "      <td>1.411090</td>\n",
              "      <td>2.06062</td>\n",
              "      <td>-0.023154</td>\n",
              "      <td>0.011234</td>\n",
              "      <td>2.155530</td>\n",
              "      <td>0.914518</td>\n",
              "      <td>0.044521</td>\n",
              "      <td>0.375731</td>\n",
              "      <td>0.134351</td>\n",
              "      <td>0.013781</td>\n",
              "      <td>1.91059</td>\n",
              "      <td>-0.042943</td>\n",
              "      <td>0.105616</td>\n",
              "      <td>0.125072</td>\n",
              "      <td>0.037509</td>\n",
              "      <td>1.043790</td>\n",
              "      <td>1.07481</td>\n",
              "      <td>-0.012819</td>\n",
              "      <td>0.072798</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id        f0       f1        f2  ...      f97       f98       f99  target\n",
              "0   0  0.106643  3.59437  132.8040  ...  1.97877  0.085974  0.240496       0\n",
              "1   1  0.125021  1.67336   76.5336  ...  2.57786 -0.020877  0.024719       0\n",
              "2   2  0.036330  1.49747  233.5460  ...  2.14112  0.124464  0.148209       0\n",
              "3   3 -0.014077  0.24600  779.9670  ...  1.96860  0.040017  0.044873       0\n",
              "4   4 -0.003259  3.71542  156.1280  ...  1.07481 -0.012819  0.072798       1\n",
              "\n",
              "[5 rows x 102 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M60zrFO7NmmP",
        "outputId": "40975209-1bd5-49fd-9449-6808d6e8e119"
      },
      "source": [
        "#Modify data type to reduce dataframe size to ease processing load.\n",
        "for column in train:\n",
        "  c_min = train[column].min()\n",
        "  c_max = train[column].max()\n",
        "  if train[column].dtype=='float64':\n",
        "     if (\n",
        "        c_min > np.finfo(np.float16).min\n",
        "        and c_max < np.finfo(np.float16).max\n",
        "     ):\n",
        "        train[column] = train[column].astype(np.float16)\n",
        "     else: train[column] = train[column].astype(np.float32)   \n",
        "    #df[column]=pd.to_numeric(df[column], downcast='float16')\n",
        "  if train[column].dtype=='int64':\n",
        "    train[column]=pd.to_numeric(train[column], downcast='integer')\n",
        "train.info(memory_usage='deep') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600000 entries, 0 to 599999\n",
            "Columns: 102 entries, id to target\n",
            "dtypes: float16(100), int32(1), int8(1)\n",
            "memory usage: 117.3 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lKZHWoIFVB-",
        "outputId": "422d9a4d-128c-42ae-8ab5-ec4ce8f81dbb"
      },
      "source": [
        "#scaler = MinMaxScaler()\n",
        "scaler = StandardScaler()\n",
        "train_scaled = pd.DataFrame(scaler.fit_transform(train.iloc[:,1:101]))\n",
        "test_scaled = pd.DataFrame(scaler.fit_transform(test.iloc[:,1:101]))\n",
        "X = train.iloc[:,1:101]\n",
        "y = train['target']\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "pd.DataFrame(train).info(memory_usage='deep') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 600000 entries, 0 to 599999\n",
            "Columns: 102 entries, id to target\n",
            "dtypes: float64(100), int64(2)\n",
            "memory usage: 466.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI8hLq4lSqAA"
      },
      "source": [
        "import sklearn.model_selection\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.25,random_state=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XzLY-1Bbqi2"
      },
      "source": [
        "Keras Sequaential()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub6tfiznb7dg"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzbwTY0BbpOT"
      },
      "source": [
        "nnetwork = models.Sequential()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RMj_gNwbpaD"
      },
      "source": [
        "nnetwork.add(layers.Dense(units=32, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01), input_shape=(100,)))\n",
        "nnetwork.add(layers.Dense(units=32, activation=\"relu\"))\n",
        "#nnetwork.add(layers.Dense(units=10))\n",
        "nnetwork.add(layers.Dense(units=32, activation=\"relu\"))\n",
        "nnetwork.add(layers.Dense(units=1, activation=\"sigmoid\"))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RRbH1oxbpdw"
      },
      "source": [
        "nnetwork.compile(loss=\"binary_crossentropy\", \n",
        "optimizer=\"adam\", \n",
        "metrics=[\"accuracy\"])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTE_9AGrbphC"
      },
      "source": [
        "#Train neural network.\n",
        "history = nnetwork.fit(X_train,\n",
        "y_train, \n",
        "epochs=50,\n",
        "verbose=1,\n",
        "batch_size=50,\n",
        "validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbmp-7c-bpj_",
        "outputId": "ca2e357e-7ad6-4d0a-8b2c-f896b6253efa"
      },
      "source": [
        "#Predict\n",
        "preds = nnetwork.predict(test_scaled)\n",
        "preds"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.72424215],\n",
              "       [0.7257259 ],\n",
              "       [0.7448243 ],\n",
              "       ...,\n",
              "       [0.73422027],\n",
              "       [0.72339463],\n",
              "       [0.7374708 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "UTfz8SybbpnQ",
        "outputId": "e0633988-8a24-4a4f-8a23-c6fe4644610b"
      },
      "source": [
        "training_loss = history.history[\"loss\"]\n",
        "test_loss = history.history[\"val_loss\"]\n",
        "epoch_count = range(1, len(training_loss)+1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e1e4699f436c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nB1SE2c1bpp6",
        "outputId": "c90a8496-cb0c-4e6f-b4a8-1513768189b3"
      },
      "source": [
        "plt.plot(epoch_count, training_loss, \"r--\")\n",
        "plt.plot(epoch_count, test_loss, \"b-\")\n",
        "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f80310237d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8031023ad0>]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8031024950>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXs4r47sbpsl"
      },
      "source": [
        "training_accuracy = history.history[\"accuracy\"]\n",
        "test_accuracy = history.history[\"val_accuracy\"]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "LqgeJccibpwG",
        "outputId": "d09e1d67-020b-4ef9-c9bd-a85960c4ca15"
      },
      "source": [
        "plt.plot(epoch_count, training_accuracy, \"r--\")\n",
        "plt.plot(epoch_count, test_accuracy, \"b-\")\n",
        "plt.legend([\"Training Accuracy\", \"Test Accuracy\"])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8030eb6b50>]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8030ec2110>]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8030eb6f90>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ADRvQ8qs-I-"
      },
      "source": [
        "Keras Sequaential() with pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0sLwaHXs9Zr"
      },
      "source": [
        "# Importing libraries for building the neural network\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PesZQRFbs9c0"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBlndVsws9f4"
      },
      "source": [
        "# Baseline model for the neural network. We choose a hidden layer of 10 neurons. The lesser number of neurons helps to eliminate the redundancies in the data and select the more important features.\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8, input_dim=100, kernel_initializer='normal', activation='tanh')) #10 perceptrons 8\n",
        "    model.add(Dropout(0.3)) #new\n",
        "    model.add(Dense(16, kernel_initializer='normal', activation='tanh')) #10 perceptrons added layer, 16 optimal\n",
        "    model.add(Dropout(0.3)) #new\n",
        "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "    # Compile model. We use the the logarithmic loss function, and the Adam gradient optimizer.  \n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) #optimizer=adam\n",
        "    return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk7-xNK3s9it",
        "outputId": "b4039d33-7e32-4356-a9fd-5a26d207b506"
      },
      "source": [
        "# Evaluate model using standardized dataset. \n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=600, verbose=1, validation_split=0.3, random_state=24))) #batch size = 500 on best\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True) #5 splits\n",
        "results = cross_val_score(pipeline, X, y, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.6056 - accuracy: 0.7110 - val_loss: 0.5879 - val_accuracy: 0.7349\n",
            "Epoch 2/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5803 - accuracy: 0.7409 - val_loss: 0.5789 - val_accuracy: 0.7380\n",
            "Epoch 3/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5752 - accuracy: 0.7437 - val_loss: 0.5761 - val_accuracy: 0.7394\n",
            "Epoch 4/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5732 - accuracy: 0.7446 - val_loss: 0.5746 - val_accuracy: 0.7397\n",
            "Epoch 5/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5721 - accuracy: 0.7450 - val_loss: 0.5737 - val_accuracy: 0.7402\n",
            "Epoch 6/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5709 - accuracy: 0.7452 - val_loss: 0.5730 - val_accuracy: 0.7406\n",
            "Epoch 7/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5702 - accuracy: 0.7454 - val_loss: 0.5726 - val_accuracy: 0.7405\n",
            "Epoch 8/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.7457 - val_loss: 0.5727 - val_accuracy: 0.7408\n",
            "Epoch 9/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.7458 - val_loss: 0.5718 - val_accuracy: 0.7412\n",
            "Epoch 10/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.7458 - val_loss: 0.5716 - val_accuracy: 0.7415\n",
            "Epoch 11/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.7462 - val_loss: 0.5715 - val_accuracy: 0.7410\n",
            "Epoch 12/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.7463 - val_loss: 0.5718 - val_accuracy: 0.7408\n",
            "Epoch 13/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.7462 - val_loss: 0.5711 - val_accuracy: 0.7412\n",
            "Epoch 14/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.7462 - val_loss: 0.5711 - val_accuracy: 0.7413\n",
            "Epoch 15/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7463 - val_loss: 0.5708 - val_accuracy: 0.7419\n",
            "Epoch 16/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7465 - val_loss: 0.5709 - val_accuracy: 0.7415\n",
            "Epoch 17/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5709 - val_accuracy: 0.7414\n",
            "Epoch 18/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7466 - val_loss: 0.5705 - val_accuracy: 0.7418\n",
            "Epoch 19/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7463 - val_loss: 0.5706 - val_accuracy: 0.7417\n",
            "Epoch 20/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5705 - val_accuracy: 0.7416\n",
            "Epoch 21/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5704 - val_accuracy: 0.7417\n",
            "Epoch 22/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7465 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 23/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5703 - val_accuracy: 0.7417\n",
            "Epoch 24/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5703 - val_accuracy: 0.7418\n",
            "Epoch 25/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5701 - val_accuracy: 0.7421\n",
            "Epoch 26/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5701 - val_accuracy: 0.7422\n",
            "Epoch 27/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7467 - val_loss: 0.5702 - val_accuracy: 0.7418\n",
            "Epoch 28/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7467 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 29/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5700 - val_accuracy: 0.7421\n",
            "Epoch 30/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5705 - val_accuracy: 0.7415\n",
            "Epoch 31/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5698 - val_accuracy: 0.7426\n",
            "Epoch 32/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5698 - val_accuracy: 0.7421\n",
            "Epoch 33/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 34/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7468 - val_loss: 0.5703 - val_accuracy: 0.7418\n",
            "Epoch 35/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5701 - val_accuracy: 0.7418\n",
            "Epoch 36/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5699 - val_accuracy: 0.7423\n",
            "Epoch 37/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7466 - val_loss: 0.5700 - val_accuracy: 0.7423\n",
            "Epoch 38/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 39/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5701 - val_accuracy: 0.7423\n",
            "Epoch 40/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 41/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5698 - val_accuracy: 0.7422\n",
            "Epoch 42/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5698 - val_accuracy: 0.7425\n",
            "Epoch 43/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5701 - val_accuracy: 0.7418\n",
            "Epoch 44/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5703 - val_accuracy: 0.7421\n",
            "Epoch 45/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5700 - val_accuracy: 0.7423\n",
            "Epoch 46/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5700 - val_accuracy: 0.7422\n",
            "Epoch 47/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5702 - val_accuracy: 0.7419\n",
            "Epoch 48/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5700 - val_accuracy: 0.7420\n",
            "Epoch 49/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5699 - val_accuracy: 0.7425\n",
            "Epoch 50/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5700 - val_accuracy: 0.7419\n",
            "Epoch 51/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5701 - val_accuracy: 0.7419\n",
            "Epoch 52/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7471 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 53/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 54/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 55/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5701 - val_accuracy: 0.7424\n",
            "Epoch 56/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 57/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5697 - val_accuracy: 0.7424\n",
            "Epoch 58/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 59/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 60/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 61/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5698 - val_accuracy: 0.7427\n",
            "Epoch 62/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5698 - val_accuracy: 0.7424\n",
            "Epoch 63/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5698 - val_accuracy: 0.7426\n",
            "Epoch 64/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5699 - val_accuracy: 0.7423\n",
            "Epoch 65/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7470 - val_loss: 0.5699 - val_accuracy: 0.7421\n",
            "Epoch 66/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5696 - val_accuracy: 0.7424\n",
            "Epoch 67/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 68/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 69/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5700 - val_accuracy: 0.7421\n",
            "Epoch 70/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 71/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 72/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5699 - val_accuracy: 0.7421\n",
            "Epoch 73/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 74/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5697 - val_accuracy: 0.7423\n",
            "Epoch 75/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 76/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 77/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 78/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7473 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 79/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5700 - val_accuracy: 0.7420\n",
            "Epoch 80/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7472 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 81/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7472 - val_loss: 0.5696 - val_accuracy: 0.7428\n",
            "Epoch 82/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 83/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 84/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 85/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 86/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 87/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 88/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 89/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 90/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5697 - val_accuracy: 0.7423\n",
            "Epoch 91/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 92/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 93/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7474 - val_loss: 0.5699 - val_accuracy: 0.7423\n",
            "Epoch 94/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5697 - val_accuracy: 0.7427\n",
            "Epoch 95/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 96/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 97/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5699 - val_accuracy: 0.7421\n",
            "Epoch 98/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 99/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5697 - val_accuracy: 0.7424\n",
            "Epoch 100/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 101/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 102/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 103/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 104/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 105/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5698 - val_accuracy: 0.7428\n",
            "Epoch 106/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 107/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 108/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 109/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7428\n",
            "Epoch 110/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 111/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 112/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 113/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 114/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5696 - val_accuracy: 0.7429\n",
            "Epoch 115/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 116/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 117/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 118/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 119/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 120/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 121/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 122/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 123/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5697 - val_accuracy: 0.7427\n",
            "Epoch 124/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5698 - val_accuracy: 0.7426\n",
            "Epoch 125/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 126/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 127/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 128/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 129/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5698 - val_accuracy: 0.7422\n",
            "Epoch 130/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 131/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 132/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 133/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 134/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 135/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 136/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 137/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 138/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 139/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 140/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 141/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 142/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5698 - val_accuracy: 0.7422\n",
            "Epoch 143/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 144/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 145/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 146/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5697 - val_accuracy: 0.7431\n",
            "Epoch 147/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 148/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 149/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 150/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 151/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 152/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 153/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 154/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 155/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 156/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 157/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 158/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 159/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 160/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5694 - val_accuracy: 0.7433\n",
            "Epoch 161/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 162/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 163/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 164/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 165/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 166/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 167/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 168/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 169/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 170/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 171/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 172/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 173/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 174/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 175/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 176/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 177/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 178/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 179/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 180/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 181/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 182/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5695 - val_accuracy: 0.7425\n",
            "Epoch 183/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 184/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 185/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 186/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 187/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
            "Epoch 188/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7435\n",
            "Epoch 189/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5695 - val_accuracy: 0.7430\n",
            "Epoch 190/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 191/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 192/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7433\n",
            "Epoch 193/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 194/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5692 - val_accuracy: 0.7435\n",
            "Epoch 195/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 196/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 197/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 198/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 199/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 200/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 201/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 202/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 203/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7433\n",
            "Epoch 204/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 205/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 206/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 207/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 208/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 209/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 210/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 211/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5694 - val_accuracy: 0.7430\n",
            "Epoch 212/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 213/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 214/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 215/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 216/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 217/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 218/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 219/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 220/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 221/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 222/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 223/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 224/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 225/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 226/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 227/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 228/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 229/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7435\n",
            "Epoch 230/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 231/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 232/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5695 - val_accuracy: 0.7432\n",
            "Epoch 233/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
            "Epoch 234/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
            "Epoch 235/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5693 - val_accuracy: 0.7434\n",
            "Epoch 236/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5696 - val_accuracy: 0.7430\n",
            "Epoch 237/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 238/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 239/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 240/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 241/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 242/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 243/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 244/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5692 - val_accuracy: 0.7434\n",
            "Epoch 245/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 246/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 247/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 248/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 249/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 250/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7483 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 251/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7434\n",
            "Epoch 252/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
            "Epoch 253/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 254/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 255/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 256/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 257/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 258/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 259/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 260/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 261/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5691 - val_accuracy: 0.7435\n",
            "Epoch 262/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 263/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 264/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 265/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 266/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7438\n",
            "Epoch 267/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 268/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 269/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7435\n",
            "Epoch 270/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 271/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 272/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 273/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 274/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7438\n",
            "Epoch 275/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7483 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 276/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 277/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 278/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5692 - val_accuracy: 0.7433\n",
            "Epoch 279/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 280/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 281/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 282/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 283/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 284/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 285/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 286/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 287/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 288/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 289/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5693 - val_accuracy: 0.7433\n",
            "Epoch 290/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 291/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7437\n",
            "Epoch 292/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 293/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 294/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 295/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 296/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 297/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 298/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 299/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 300/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "200/200 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.6062 - accuracy: 0.7123 - val_loss: 0.5868 - val_accuracy: 0.7357\n",
            "Epoch 2/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5803 - accuracy: 0.7407 - val_loss: 0.5780 - val_accuracy: 0.7395\n",
            "Epoch 3/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5754 - accuracy: 0.7433 - val_loss: 0.5754 - val_accuracy: 0.7403\n",
            "Epoch 4/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5735 - accuracy: 0.7443 - val_loss: 0.5742 - val_accuracy: 0.7400\n",
            "Epoch 5/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5727 - accuracy: 0.7448 - val_loss: 0.5728 - val_accuracy: 0.7417\n",
            "Epoch 6/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.7450 - val_loss: 0.5725 - val_accuracy: 0.7411\n",
            "Epoch 7/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5709 - accuracy: 0.7452 - val_loss: 0.5721 - val_accuracy: 0.7414\n",
            "Epoch 8/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5699 - accuracy: 0.7456 - val_loss: 0.5715 - val_accuracy: 0.7415\n",
            "Epoch 9/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.7455 - val_loss: 0.5714 - val_accuracy: 0.7416\n",
            "Epoch 10/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5695 - accuracy: 0.7456 - val_loss: 0.5708 - val_accuracy: 0.7419\n",
            "Epoch 11/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.7459 - val_loss: 0.5708 - val_accuracy: 0.7425\n",
            "Epoch 12/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5691 - accuracy: 0.7458 - val_loss: 0.5706 - val_accuracy: 0.7420\n",
            "Epoch 13/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7459 - val_loss: 0.5703 - val_accuracy: 0.7422\n",
            "Epoch 14/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7459 - val_loss: 0.5707 - val_accuracy: 0.7412\n",
            "Epoch 15/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.7458 - val_loss: 0.5702 - val_accuracy: 0.7422\n",
            "Epoch 16/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7463 - val_loss: 0.5699 - val_accuracy: 0.7424\n",
            "Epoch 17/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7461 - val_loss: 0.5698 - val_accuracy: 0.7424\n",
            "Epoch 18/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7462 - val_loss: 0.5699 - val_accuracy: 0.7421\n",
            "Epoch 19/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7460 - val_loss: 0.5699 - val_accuracy: 0.7424\n",
            "Epoch 20/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5698 - val_accuracy: 0.7425\n",
            "Epoch 21/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7463 - val_loss: 0.5697 - val_accuracy: 0.7427\n",
            "Epoch 22/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7462 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 23/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7465 - val_loss: 0.5698 - val_accuracy: 0.7421\n",
            "Epoch 24/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7461 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 25/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7464 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 26/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 27/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 28/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7463 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 29/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 30/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7465 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 31/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 32/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 33/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7465 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 34/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 35/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7465 - val_loss: 0.5691 - val_accuracy: 0.7429\n",
            "Epoch 36/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7466 - val_loss: 0.5693 - val_accuracy: 0.7426\n",
            "Epoch 37/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 38/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 39/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 40/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 41/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 42/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 43/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7467 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 44/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 45/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 46/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 47/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 48/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5693 - val_accuracy: 0.7426\n",
            "Epoch 49/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7467 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 50/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 51/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 52/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7467 - val_loss: 0.5692 - val_accuracy: 0.7428\n",
            "Epoch 53/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5691 - val_accuracy: 0.7429\n",
            "Epoch 54/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 55/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 56/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 57/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 58/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7468 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 59/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7468 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 60/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 61/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 62/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 63/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 64/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 65/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 66/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 67/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 68/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 69/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 70/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5693 - val_accuracy: 0.7432\n",
            "Epoch 71/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5692 - val_accuracy: 0.7428\n",
            "Epoch 72/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 73/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 74/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 75/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 76/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 77/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 78/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7470 - val_loss: 0.5692 - val_accuracy: 0.7434\n",
            "Epoch 79/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5692 - val_accuracy: 0.7434\n",
            "Epoch 80/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7469 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 81/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 82/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5695 - val_accuracy: 0.7424\n",
            "Epoch 83/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 84/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 85/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 86/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 87/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 88/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 89/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 90/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 91/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 92/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 93/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7439\n",
            "Epoch 94/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 95/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 96/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 97/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 98/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 99/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 100/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 101/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 102/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7471 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 103/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 104/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 105/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 106/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 107/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 108/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 109/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 110/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 111/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 112/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 113/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 114/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 115/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 116/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 117/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 118/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 119/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 120/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 121/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 122/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5692 - val_accuracy: 0.7435\n",
            "Epoch 123/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 124/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 125/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 126/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 127/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 128/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 129/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 130/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 131/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 132/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 133/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 134/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 135/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 136/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 137/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 138/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 139/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 140/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 141/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 142/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 143/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 144/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 145/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 146/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 147/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 148/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 149/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 150/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 151/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 152/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 153/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 154/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 155/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 156/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 157/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 158/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 159/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 160/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7439\n",
            "Epoch 161/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 162/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 163/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 164/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 165/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7439\n",
            "Epoch 166/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 167/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 168/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 169/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 170/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 171/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 172/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 173/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 174/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 175/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 176/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 177/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 178/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 179/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 180/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 181/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 182/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 183/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 184/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 185/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 186/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 187/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 188/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 189/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 190/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 191/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 192/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 193/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 194/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 195/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 196/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 197/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 198/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 199/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 200/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 201/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 202/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 203/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 204/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 205/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 206/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 207/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 208/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7440\n",
            "Epoch 209/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 210/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 211/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 212/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 213/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 214/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 215/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 216/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 217/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 218/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 219/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 220/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 221/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 222/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 223/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 224/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 225/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 226/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 227/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 228/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 229/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 230/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 231/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 232/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 233/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 234/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 235/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 236/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 237/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 238/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7442\n",
            "Epoch 239/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 240/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 241/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 242/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7443\n",
            "Epoch 243/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 244/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 245/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 246/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 247/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 248/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 249/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 250/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 251/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 252/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 253/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 254/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 255/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 256/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 257/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 258/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 259/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 260/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 261/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 262/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 263/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 264/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 265/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 266/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5688 - val_accuracy: 0.7439\n",
            "Epoch 267/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 268/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 269/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 270/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7443\n",
            "Epoch 271/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7445\n",
            "Epoch 272/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 273/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 274/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 275/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 276/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 277/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 278/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 279/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 280/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 281/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 282/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 283/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 284/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 285/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 286/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 287/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7445\n",
            "Epoch 288/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5678 - val_accuracy: 0.7447\n",
            "Epoch 289/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 290/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 291/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 292/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 293/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 294/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 295/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 296/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 297/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7444\n",
            "Epoch 298/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 299/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 300/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "200/200 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.6055 - accuracy: 0.7123 - val_loss: 0.5869 - val_accuracy: 0.7349\n",
            "Epoch 2/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5806 - accuracy: 0.7409 - val_loss: 0.5779 - val_accuracy: 0.7392\n",
            "Epoch 3/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5753 - accuracy: 0.7436 - val_loss: 0.5751 - val_accuracy: 0.7400\n",
            "Epoch 4/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5735 - accuracy: 0.7444 - val_loss: 0.5735 - val_accuracy: 0.7414\n",
            "Epoch 5/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5725 - accuracy: 0.7448 - val_loss: 0.5729 - val_accuracy: 0.7412\n",
            "Epoch 6/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.7448 - val_loss: 0.5716 - val_accuracy: 0.7424\n",
            "Epoch 7/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5711 - accuracy: 0.7453 - val_loss: 0.5714 - val_accuracy: 0.7423\n",
            "Epoch 8/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5705 - accuracy: 0.7455 - val_loss: 0.5709 - val_accuracy: 0.7423\n",
            "Epoch 9/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5702 - accuracy: 0.7455 - val_loss: 0.5708 - val_accuracy: 0.7425\n",
            "Epoch 10/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5698 - accuracy: 0.7457 - val_loss: 0.5709 - val_accuracy: 0.7415\n",
            "Epoch 11/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.7457 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 12/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.7460 - val_loss: 0.5707 - val_accuracy: 0.7417\n",
            "Epoch 13/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.7461 - val_loss: 0.5700 - val_accuracy: 0.7426\n",
            "Epoch 14/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5688 - accuracy: 0.7460 - val_loss: 0.5698 - val_accuracy: 0.7426\n",
            "Epoch 15/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5689 - accuracy: 0.7461 - val_loss: 0.5699 - val_accuracy: 0.7426\n",
            "Epoch 16/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7462 - val_loss: 0.5697 - val_accuracy: 0.7427\n",
            "Epoch 17/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7461 - val_loss: 0.5696 - val_accuracy: 0.7428\n",
            "Epoch 18/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7459 - val_loss: 0.5695 - val_accuracy: 0.7429\n",
            "Epoch 19/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 20/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7461 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
            "Epoch 21/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7463 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 22/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 23/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7465 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 24/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 25/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7463 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 26/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 27/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 28/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5691 - val_accuracy: 0.7429\n",
            "Epoch 29/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7463 - val_loss: 0.5695 - val_accuracy: 0.7430\n",
            "Epoch 30/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 31/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7465 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 32/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7465 - val_loss: 0.5690 - val_accuracy: 0.7428\n",
            "Epoch 33/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7428\n",
            "Epoch 34/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 35/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 36/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 37/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7467 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 38/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 39/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7469 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 40/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 41/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5686 - val_accuracy: 0.7434\n",
            "Epoch 42/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5695 - val_accuracy: 0.7431\n",
            "Epoch 43/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7429\n",
            "Epoch 44/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 45/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 46/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 47/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 48/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5695 - val_accuracy: 0.7431\n",
            "Epoch 49/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7468 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 50/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7466 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 51/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 52/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 53/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 54/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 55/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 56/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 57/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 58/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 59/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 60/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 61/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 62/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 63/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 64/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 65/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 66/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 67/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 68/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7468 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 69/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 70/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 71/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 72/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 73/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7439\n",
            "Epoch 74/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5690 - val_accuracy: 0.7437\n",
            "Epoch 75/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 76/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 77/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 78/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 79/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 80/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 81/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 82/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 83/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 84/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 85/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 86/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 87/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 88/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7434\n",
            "Epoch 89/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 90/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 91/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 92/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 93/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5686 - val_accuracy: 0.7434\n",
            "Epoch 94/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 95/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 96/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 97/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 98/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 99/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 100/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 101/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 102/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 103/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 104/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 105/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 106/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 107/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 108/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 109/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 110/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 111/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 112/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 113/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 114/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 115/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 116/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 117/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 118/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 119/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 120/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7435\n",
            "Epoch 121/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 122/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 123/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 124/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 125/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 126/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 127/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 128/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 129/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 130/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5686 - val_accuracy: 0.7434\n",
            "Epoch 131/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 132/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 133/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 134/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 135/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 136/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5683 - val_accuracy: 0.7437\n",
            "Epoch 137/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 138/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 139/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7433\n",
            "Epoch 140/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 141/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 142/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 143/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 144/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7474 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 145/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 146/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 147/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 148/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 149/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 150/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 151/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 152/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 153/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 154/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 155/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 156/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 157/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 158/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 159/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 160/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 161/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 162/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 163/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 164/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 165/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 166/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 167/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 168/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 169/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 170/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 171/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 172/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 173/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 174/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7441\n",
            "Epoch 175/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 176/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 177/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 178/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 179/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 180/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 181/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 182/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 183/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 184/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 185/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 186/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 187/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 188/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 189/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 190/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 191/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 192/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 193/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 194/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 195/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 196/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 197/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 198/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 199/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 200/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 201/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 202/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 203/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 204/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 205/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 206/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 207/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 208/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 209/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 210/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 211/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 212/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 213/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 214/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 215/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 216/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 217/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 218/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 219/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 220/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 221/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 222/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 223/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 224/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 225/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 226/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 227/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 228/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 229/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 230/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 231/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 232/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 233/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 234/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 235/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 236/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 237/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7441\n",
            "Epoch 238/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 239/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 240/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 241/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 242/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 243/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 244/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 245/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 246/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 247/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 248/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 249/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 250/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 251/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 252/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 253/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 254/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 255/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 256/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 257/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7441\n",
            "Epoch 258/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 259/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 260/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 261/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 262/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 263/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 264/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 265/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 266/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 267/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 268/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 269/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 270/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 271/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 272/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 273/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7446\n",
            "Epoch 274/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 275/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7444\n",
            "Epoch 276/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 277/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 278/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 279/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 280/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 281/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 282/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 283/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 284/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 285/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 286/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 287/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 288/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 289/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7477 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 290/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 291/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 292/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 293/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 294/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 295/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 296/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 297/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 298/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7445\n",
            "Epoch 299/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 300/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "200/200 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "560/560 [==============================] - 3s 4ms/step - loss: 0.6059 - accuracy: 0.7120 - val_loss: 0.5862 - val_accuracy: 0.7361\n",
            "Epoch 2/300\n",
            "560/560 [==============================] - 4s 7ms/step - loss: 0.5804 - accuracy: 0.7409 - val_loss: 0.5773 - val_accuracy: 0.7405\n",
            "Epoch 3/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5757 - accuracy: 0.7432 - val_loss: 0.5747 - val_accuracy: 0.7407\n",
            "Epoch 4/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5736 - accuracy: 0.7440 - val_loss: 0.5731 - val_accuracy: 0.7423\n",
            "Epoch 5/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5726 - accuracy: 0.7443 - val_loss: 0.5722 - val_accuracy: 0.7423\n",
            "Epoch 6/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.7446 - val_loss: 0.5718 - val_accuracy: 0.7418\n",
            "Epoch 7/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5711 - accuracy: 0.7448 - val_loss: 0.5710 - val_accuracy: 0.7422\n",
            "Epoch 8/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5706 - accuracy: 0.7450 - val_loss: 0.5707 - val_accuracy: 0.7428\n",
            "Epoch 9/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5701 - accuracy: 0.7454 - val_loss: 0.5707 - val_accuracy: 0.7420\n",
            "Epoch 10/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5698 - accuracy: 0.7452 - val_loss: 0.5703 - val_accuracy: 0.7425\n",
            "Epoch 11/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5698 - accuracy: 0.7454 - val_loss: 0.5698 - val_accuracy: 0.7429\n",
            "Epoch 12/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5694 - accuracy: 0.7456 - val_loss: 0.5701 - val_accuracy: 0.7429\n",
            "Epoch 13/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.7458 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 14/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.7458 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 15/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5689 - accuracy: 0.7459 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 16/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7462 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 17/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7460 - val_loss: 0.5691 - val_accuracy: 0.7435\n",
            "Epoch 18/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5689 - accuracy: 0.7459 - val_loss: 0.5690 - val_accuracy: 0.7437\n",
            "Epoch 19/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7461 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 20/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7460 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 21/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7460 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 22/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7461 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 23/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 24/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 25/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7462 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 26/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 27/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7462 - val_loss: 0.5687 - val_accuracy: 0.7433\n",
            "Epoch 28/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7463 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 29/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 30/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7464 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 31/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7461 - val_loss: 0.5685 - val_accuracy: 0.7435\n",
            "Epoch 32/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7464 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 33/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 34/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7464 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 35/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 36/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7464 - val_loss: 0.5683 - val_accuracy: 0.7437\n",
            "Epoch 37/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7465 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 38/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5682 - val_accuracy: 0.7439\n",
            "Epoch 39/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7464 - val_loss: 0.5684 - val_accuracy: 0.7436\n",
            "Epoch 40/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7464 - val_loss: 0.5682 - val_accuracy: 0.7439\n",
            "Epoch 41/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5687 - val_accuracy: 0.7433\n",
            "Epoch 42/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7465 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 43/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 44/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7465 - val_loss: 0.5683 - val_accuracy: 0.7437\n",
            "Epoch 45/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7465 - val_loss: 0.5681 - val_accuracy: 0.7440\n",
            "Epoch 46/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7466 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 47/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5687 - val_accuracy: 0.7431\n",
            "Epoch 48/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5683 - val_accuracy: 0.7437\n",
            "Epoch 49/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 50/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7465 - val_loss: 0.5681 - val_accuracy: 0.7439\n",
            "Epoch 51/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5686 - val_accuracy: 0.7433\n",
            "Epoch 52/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 53/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 54/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5682 - val_accuracy: 0.7439\n",
            "Epoch 55/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7466 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 56/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 57/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 58/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 59/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7465 - val_loss: 0.5679 - val_accuracy: 0.7441\n",
            "Epoch 60/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5681 - val_accuracy: 0.7438\n",
            "Epoch 61/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7439\n",
            "Epoch 62/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 63/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7467 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 64/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 65/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 66/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7468 - val_loss: 0.5682 - val_accuracy: 0.7438\n",
            "Epoch 67/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5682 - val_accuracy: 0.7439\n",
            "Epoch 68/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5684 - val_accuracy: 0.7436\n",
            "Epoch 69/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7465 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 70/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5682 - val_accuracy: 0.7438\n",
            "Epoch 71/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5681 - val_accuracy: 0.7440\n",
            "Epoch 72/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7469 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 73/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 74/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 75/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 76/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5680 - val_accuracy: 0.7441\n",
            "Epoch 77/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 78/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 79/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 80/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7470 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 81/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5681 - val_accuracy: 0.7439\n",
            "Epoch 82/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 83/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 84/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 85/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5678 - val_accuracy: 0.7443\n",
            "Epoch 86/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 87/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 88/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7468 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 89/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7441\n",
            "Epoch 90/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 91/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 92/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7470 - val_loss: 0.5680 - val_accuracy: 0.7440\n",
            "Epoch 93/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5677 - val_accuracy: 0.7444\n",
            "Epoch 94/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 95/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 96/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 97/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5679 - val_accuracy: 0.7441\n",
            "Epoch 98/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
            "Epoch 99/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 100/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7470 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 101/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 102/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
            "Epoch 103/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 104/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 105/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 106/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 107/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7469 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 108/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 109/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5680 - val_accuracy: 0.7440\n",
            "Epoch 110/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 111/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5679 - val_accuracy: 0.7442\n",
            "Epoch 112/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 113/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5681 - val_accuracy: 0.7440\n",
            "Epoch 114/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
            "Epoch 115/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7470 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 116/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 117/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 118/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 119/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 120/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 121/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 122/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7442\n",
            "Epoch 123/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 124/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 125/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 126/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 127/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5679 - val_accuracy: 0.7447\n",
            "Epoch 128/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 129/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 130/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5677 - val_accuracy: 0.7444\n",
            "Epoch 131/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5681 - val_accuracy: 0.7445\n",
            "Epoch 132/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7446\n",
            "Epoch 133/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 134/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 135/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 136/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 137/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 138/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 139/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 140/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 141/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 142/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 143/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 144/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 145/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 146/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 147/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 148/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 149/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 150/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5679 - val_accuracy: 0.7441\n",
            "Epoch 151/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7442\n",
            "Epoch 152/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7474 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 153/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5679 - val_accuracy: 0.7443\n",
            "Epoch 154/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5680 - val_accuracy: 0.7441\n",
            "Epoch 155/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 156/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 157/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 158/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 159/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 160/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7450\n",
            "Epoch 161/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 162/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 163/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 164/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 165/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 166/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 167/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5673 - val_accuracy: 0.7451\n",
            "Epoch 168/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 169/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5679 - val_accuracy: 0.7444\n",
            "Epoch 170/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 171/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 172/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 173/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 174/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7472 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 175/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5674 - val_accuracy: 0.7449\n",
            "Epoch 176/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7476 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 177/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 178/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 179/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5673 - val_accuracy: 0.7450\n",
            "Epoch 180/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 181/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7475 - val_loss: 0.5678 - val_accuracy: 0.7445\n",
            "Epoch 182/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 183/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 184/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 185/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 186/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 187/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 188/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7450\n",
            "Epoch 189/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7473 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 190/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 191/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7446\n",
            "Epoch 192/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 193/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 194/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 195/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 196/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 197/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 198/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5676 - val_accuracy: 0.7446\n",
            "Epoch 199/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5679 - val_accuracy: 0.7445\n",
            "Epoch 200/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5680 - val_accuracy: 0.7445\n",
            "Epoch 201/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 202/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 203/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 204/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 205/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 206/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7449\n",
            "Epoch 207/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 208/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5678 - val_accuracy: 0.7443\n",
            "Epoch 209/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7444\n",
            "Epoch 210/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 211/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7446\n",
            "Epoch 212/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7474 - val_loss: 0.5673 - val_accuracy: 0.7451\n",
            "Epoch 213/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 214/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 215/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5673 - val_accuracy: 0.7451\n",
            "Epoch 216/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 217/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 218/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 219/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7474 - val_loss: 0.5674 - val_accuracy: 0.7451\n",
            "Epoch 220/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 221/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 222/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 223/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 224/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 225/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 226/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 227/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5673 - val_accuracy: 0.7452\n",
            "Epoch 228/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5673 - val_accuracy: 0.7453\n",
            "Epoch 229/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 230/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 231/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 232/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 233/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 234/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 235/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 236/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 237/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 238/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 239/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 240/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 241/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 242/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 243/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7451\n",
            "Epoch 244/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7450\n",
            "Epoch 245/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5673 - val_accuracy: 0.7452\n",
            "Epoch 246/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 247/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 248/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 249/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5680 - val_accuracy: 0.7445\n",
            "Epoch 250/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5678 - val_accuracy: 0.7444\n",
            "Epoch 251/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7450\n",
            "Epoch 252/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5673 - val_accuracy: 0.7452\n",
            "Epoch 253/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "Epoch 254/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7451\n",
            "Epoch 255/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7449\n",
            "Epoch 256/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
            "Epoch 257/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7450\n",
            "Epoch 258/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 259/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5677 - val_accuracy: 0.7448\n",
            "Epoch 260/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 261/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 262/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 263/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 264/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5677 - val_accuracy: 0.7446\n",
            "Epoch 265/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 266/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7448\n",
            "Epoch 267/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7449\n",
            "Epoch 268/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5673 - val_accuracy: 0.7450\n",
            "Epoch 269/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5678 - val_accuracy: 0.7446\n",
            "Epoch 270/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5672 - val_accuracy: 0.7454\n",
            "Epoch 271/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 272/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7451\n",
            "Epoch 273/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5677 - val_accuracy: 0.7449\n",
            "Epoch 274/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 275/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 276/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 277/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7475 - val_loss: 0.5677 - val_accuracy: 0.7445\n",
            "Epoch 278/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 279/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7449\n",
            "Epoch 280/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7447\n",
            "Epoch 281/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7475 - val_loss: 0.5676 - val_accuracy: 0.7448\n",
            "Epoch 282/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 283/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5677 - val_accuracy: 0.7447\n",
            "Epoch 284/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5673 - val_accuracy: 0.7452\n",
            "Epoch 285/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5673 - val_accuracy: 0.7451\n",
            "Epoch 286/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7450\n",
            "Epoch 287/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5673 - val_accuracy: 0.7452\n",
            "Epoch 288/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5678 - val_accuracy: 0.7450\n",
            "Epoch 289/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7448\n",
            "Epoch 290/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5674 - val_accuracy: 0.7449\n",
            "Epoch 291/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5675 - val_accuracy: 0.7451\n",
            "Epoch 292/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5672 - val_accuracy: 0.7453\n",
            "Epoch 293/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5676 - val_accuracy: 0.7447\n",
            "Epoch 294/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.7478 - val_loss: 0.5673 - val_accuracy: 0.7450\n",
            "Epoch 295/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5673 - val_accuracy: 0.7450\n",
            "Epoch 296/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5674 - val_accuracy: 0.7451\n",
            "Epoch 297/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5675 - accuracy: 0.7478 - val_loss: 0.5674 - val_accuracy: 0.7452\n",
            "Epoch 298/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5672 - val_accuracy: 0.7452\n",
            "Epoch 299/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5676 - val_accuracy: 0.7449\n",
            "Epoch 300/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5675 - val_accuracy: 0.7449\n",
            "200/200 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "560/560 [==============================] - 3s 4ms/step - loss: 0.6059 - accuracy: 0.7120 - val_loss: 0.5865 - val_accuracy: 0.7347\n",
            "Epoch 2/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5800 - accuracy: 0.7415 - val_loss: 0.5777 - val_accuracy: 0.7392\n",
            "Epoch 3/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5751 - accuracy: 0.7442 - val_loss: 0.5753 - val_accuracy: 0.7394\n",
            "Epoch 4/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5730 - accuracy: 0.7449 - val_loss: 0.5742 - val_accuracy: 0.7396\n",
            "Epoch 5/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5719 - accuracy: 0.7451 - val_loss: 0.5732 - val_accuracy: 0.7407\n",
            "Epoch 6/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5710 - accuracy: 0.7454 - val_loss: 0.5727 - val_accuracy: 0.7406\n",
            "Epoch 7/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5704 - accuracy: 0.7458 - val_loss: 0.5720 - val_accuracy: 0.7409\n",
            "Epoch 8/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5700 - accuracy: 0.7458 - val_loss: 0.5717 - val_accuracy: 0.7414\n",
            "Epoch 9/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5696 - accuracy: 0.7462 - val_loss: 0.5713 - val_accuracy: 0.7416\n",
            "Epoch 10/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5693 - accuracy: 0.7462 - val_loss: 0.5713 - val_accuracy: 0.7409\n",
            "Epoch 11/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5692 - accuracy: 0.7463 - val_loss: 0.5708 - val_accuracy: 0.7419\n",
            "Epoch 12/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5689 - accuracy: 0.7462 - val_loss: 0.5707 - val_accuracy: 0.7418\n",
            "Epoch 13/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7463 - val_loss: 0.5704 - val_accuracy: 0.7421\n",
            "Epoch 14/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7466 - val_loss: 0.5705 - val_accuracy: 0.7423\n",
            "Epoch 15/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5685 - accuracy: 0.7466 - val_loss: 0.5707 - val_accuracy: 0.7415\n",
            "Epoch 16/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7467 - val_loss: 0.5703 - val_accuracy: 0.7425\n",
            "Epoch 17/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7466 - val_loss: 0.5701 - val_accuracy: 0.7423\n",
            "Epoch 18/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5699 - val_accuracy: 0.7426\n",
            "Epoch 19/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5700 - val_accuracy: 0.7425\n",
            "Epoch 20/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5701 - val_accuracy: 0.7422\n",
            "Epoch 21/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7467 - val_loss: 0.5699 - val_accuracy: 0.7424\n",
            "Epoch 22/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7468 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 23/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5696 - val_accuracy: 0.7428\n",
            "Epoch 24/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5699 - val_accuracy: 0.7420\n",
            "Epoch 25/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5700 - val_accuracy: 0.7423\n",
            "Epoch 26/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 27/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5697 - val_accuracy: 0.7424\n",
            "Epoch 28/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5702 - val_accuracy: 0.7418\n",
            "Epoch 29/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5694 - val_accuracy: 0.7433\n",
            "Epoch 30/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7470 - val_loss: 0.5697 - val_accuracy: 0.7426\n",
            "Epoch 31/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 32/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 33/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 34/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5697 - val_accuracy: 0.7425\n",
            "Epoch 35/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5699 - val_accuracy: 0.7423\n",
            "Epoch 36/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5694 - val_accuracy: 0.7425\n",
            "Epoch 37/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5695 - val_accuracy: 0.7425\n",
            "Epoch 38/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7471 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 39/300\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 40/300\n",
            "560/560 [==============================] - 3s 6ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 41/300\n",
            "560/560 [==============================] - 3s 5ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 42/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 43/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7471 - val_loss: 0.5695 - val_accuracy: 0.7425\n",
            "Epoch 44/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7471 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 45/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5691 - val_accuracy: 0.7434\n",
            "Epoch 46/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5697 - val_accuracy: 0.7427\n",
            "Epoch 47/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5692 - val_accuracy: 0.7427\n",
            "Epoch 48/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5697 - val_accuracy: 0.7422\n",
            "Epoch 49/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5701 - val_accuracy: 0.7429\n",
            "Epoch 50/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 51/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 52/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 53/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 54/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7473 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 55/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5696 - val_accuracy: 0.7423\n",
            "Epoch 56/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 57/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7473 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 58/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 59/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5696 - val_accuracy: 0.7426\n",
            "Epoch 60/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 61/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7473 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 62/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 63/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 64/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 65/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5692 - val_accuracy: 0.7427\n",
            "Epoch 66/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7475 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 67/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5692 - val_accuracy: 0.7433\n",
            "Epoch 68/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 69/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 70/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 71/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 72/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 73/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 74/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 75/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 76/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 77/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 78/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 79/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5700 - val_accuracy: 0.7425\n",
            "Epoch 80/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 81/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 82/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 83/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 84/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 85/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 86/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 87/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 88/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 89/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5692 - val_accuracy: 0.7431\n",
            "Epoch 90/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 91/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 92/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 93/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7476 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 94/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5695 - val_accuracy: 0.7427\n",
            "Epoch 95/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5695 - val_accuracy: 0.7426\n",
            "Epoch 96/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 97/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 98/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 99/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 100/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5692 - val_accuracy: 0.7428\n",
            "Epoch 101/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 102/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 103/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 104/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 105/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 106/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 107/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 108/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 109/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 110/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 111/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5693 - val_accuracy: 0.7430\n",
            "Epoch 112/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 113/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 114/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 115/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7477 - val_loss: 0.5696 - val_accuracy: 0.7423\n",
            "Epoch 116/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5692 - val_accuracy: 0.7429\n",
            "Epoch 117/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 118/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 119/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 120/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 121/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 122/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7429\n",
            "Epoch 123/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 124/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 125/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 126/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 127/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 128/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 129/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 130/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 131/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 132/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 133/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7480 - val_loss: 0.5693 - val_accuracy: 0.7429\n",
            "Epoch 134/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 135/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 136/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 137/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 138/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7477 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 139/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 140/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 141/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 142/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 143/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 144/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 145/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 146/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 147/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 148/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 149/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 150/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 151/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 152/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7432\n",
            "Epoch 153/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 154/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 155/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 156/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 157/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 158/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 159/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 160/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7479 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 161/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 162/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 163/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 164/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 165/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 166/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 167/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 168/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 169/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 170/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7479 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 171/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 172/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 173/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 174/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7480 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 175/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 176/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 177/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 178/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 179/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 180/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 181/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 182/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 183/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 184/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 185/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 186/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 187/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 188/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 189/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 190/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 191/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 192/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 193/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 194/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 195/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 196/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 197/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 198/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 199/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 200/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 201/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7439\n",
            "Epoch 202/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 203/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 204/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 205/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 206/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 207/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 208/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 209/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 210/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 211/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 212/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 213/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 214/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 215/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 216/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 217/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 218/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 219/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 220/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 221/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 222/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 223/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 224/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 225/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 226/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7484 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 227/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 228/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 229/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 230/300\n",
            "560/560 [==============================] - 2s 4ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 231/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 232/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 233/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 234/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7482 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 235/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5685 - val_accuracy: 0.7442\n",
            "Epoch 236/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 237/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 238/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7484 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 239/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 240/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 241/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7485 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 242/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 243/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 244/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 245/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5662 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 246/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 247/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7440\n",
            "Epoch 248/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.7441\n",
            "Epoch 249/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 250/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7484 - val_loss: 0.5689 - val_accuracy: 0.7436\n",
            "Epoch 251/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7484 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 252/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 253/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 254/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 255/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 256/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 257/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7442\n",
            "Epoch 258/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 259/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7438\n",
            "Epoch 260/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 261/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 262/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 263/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 264/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 265/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 266/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 267/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 268/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 269/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7485 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 270/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7485 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 271/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7483 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 272/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 273/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 274/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 275/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7484 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 276/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 277/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 278/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 279/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 280/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 281/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 282/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7484 - val_loss: 0.5683 - val_accuracy: 0.7444\n",
            "Epoch 283/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7483 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 284/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7483 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 285/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 286/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 287/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 288/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 289/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7483 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 290/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7486 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 291/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7484 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 292/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7485 - val_loss: 0.5687 - val_accuracy: 0.7438\n",
            "Epoch 293/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7483 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 294/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7484 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 295/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7440\n",
            "Epoch 296/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7484 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 297/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7484 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 298/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5664 - accuracy: 0.7483 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 299/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 300/300\n",
            "560/560 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7482 - val_loss: 0.5687 - val_accuracy: 0.7440\n",
            "200/200 [==============================] - 0s 1ms/step\n",
            "Results: 74.72% (0.05%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BT9hpTqs9la",
        "outputId": "6e282fe3-51ce-40a7-978e-2a51e6c75a2a"
      },
      "source": [
        "history = pipeline.fit(X, y)\n",
        "#losses = history.history[\"mean_absolute_error\"]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scikeras/wrappers.py:290: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  \"``build_fn`` will be renamed to ``model`` in a future release,\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.6012 - accuracy: 0.7173 - val_loss: 0.5834 - val_accuracy: 0.7372\n",
            "Epoch 2/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5778 - accuracy: 0.7422 - val_loss: 0.5762 - val_accuracy: 0.7405\n",
            "Epoch 3/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5743 - accuracy: 0.7441 - val_loss: 0.5743 - val_accuracy: 0.7403\n",
            "Epoch 4/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5722 - accuracy: 0.7448 - val_loss: 0.5731 - val_accuracy: 0.7409\n",
            "Epoch 5/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5716 - accuracy: 0.7450 - val_loss: 0.5723 - val_accuracy: 0.7411\n",
            "Epoch 6/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5707 - accuracy: 0.7454 - val_loss: 0.5716 - val_accuracy: 0.7425\n",
            "Epoch 7/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5700 - accuracy: 0.7455 - val_loss: 0.5712 - val_accuracy: 0.7417\n",
            "Epoch 8/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5697 - accuracy: 0.7455 - val_loss: 0.5713 - val_accuracy: 0.7410\n",
            "Epoch 9/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5693 - accuracy: 0.7459 - val_loss: 0.5703 - val_accuracy: 0.7427\n",
            "Epoch 10/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5690 - accuracy: 0.7458 - val_loss: 0.5705 - val_accuracy: 0.7423\n",
            "Epoch 11/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5687 - accuracy: 0.7460 - val_loss: 0.5705 - val_accuracy: 0.7419\n",
            "Epoch 12/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7461 - val_loss: 0.5703 - val_accuracy: 0.7418\n",
            "Epoch 13/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7461 - val_loss: 0.5702 - val_accuracy: 0.7421\n",
            "Epoch 14/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7462 - val_loss: 0.5698 - val_accuracy: 0.7425\n",
            "Epoch 15/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5686 - accuracy: 0.7463 - val_loss: 0.5696 - val_accuracy: 0.7427\n",
            "Epoch 16/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7464 - val_loss: 0.5698 - val_accuracy: 0.7428\n",
            "Epoch 17/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5683 - accuracy: 0.7463 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 18/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5682 - accuracy: 0.7463 - val_loss: 0.5693 - val_accuracy: 0.7431\n",
            "Epoch 19/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7466 - val_loss: 0.5699 - val_accuracy: 0.7422\n",
            "Epoch 20/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7465 - val_loss: 0.5695 - val_accuracy: 0.7428\n",
            "Epoch 21/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7466 - val_loss: 0.5698 - val_accuracy: 0.7423\n",
            "Epoch 22/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7467 - val_loss: 0.5694 - val_accuracy: 0.7431\n",
            "Epoch 23/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5695 - val_accuracy: 0.7425\n",
            "Epoch 24/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7465 - val_loss: 0.5694 - val_accuracy: 0.7427\n",
            "Epoch 25/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 26/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 27/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7467 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 28/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5679 - accuracy: 0.7467 - val_loss: 0.5694 - val_accuracy: 0.7426\n",
            "Epoch 29/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 30/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5681 - accuracy: 0.7466 - val_loss: 0.5692 - val_accuracy: 0.7428\n",
            "Epoch 31/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5680 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 32/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5694 - val_accuracy: 0.7429\n",
            "Epoch 33/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7466 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 34/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7469 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 35/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7468 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 36/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5694 - val_accuracy: 0.7428\n",
            "Epoch 37/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7468 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 38/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 39/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5693 - val_accuracy: 0.7427\n",
            "Epoch 40/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5690 - val_accuracy: 0.7429\n",
            "Epoch 41/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 42/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 43/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5693 - val_accuracy: 0.7428\n",
            "Epoch 44/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7469 - val_loss: 0.5696 - val_accuracy: 0.7423\n",
            "Epoch 45/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7470 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 46/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5692 - val_accuracy: 0.7434\n",
            "Epoch 47/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7470 - val_loss: 0.5692 - val_accuracy: 0.7430\n",
            "Epoch 48/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7470 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 49/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 50/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 51/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5676 - accuracy: 0.7470 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 52/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 53/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 54/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 55/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7469 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 56/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 57/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 58/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5689 - val_accuracy: 0.7430\n",
            "Epoch 59/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7470 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 60/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 61/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 62/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7471 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 63/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7471 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 64/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 65/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5691 - val_accuracy: 0.7430\n",
            "Epoch 66/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 67/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 68/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7472 - val_loss: 0.5691 - val_accuracy: 0.7432\n",
            "Epoch 69/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7471 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 70/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5676 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7431\n",
            "Epoch 71/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5690 - val_accuracy: 0.7430\n",
            "Epoch 72/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 73/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 74/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 75/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7433\n",
            "Epoch 76/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7472 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 77/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7472 - val_loss: 0.5691 - val_accuracy: 0.7431\n",
            "Epoch 78/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 79/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7471 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 80/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 81/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 82/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 83/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7472 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 84/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 85/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 86/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 87/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 88/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 89/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7435\n",
            "Epoch 90/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 91/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5691 - val_accuracy: 0.7433\n",
            "Epoch 92/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 93/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 94/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 95/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5688 - val_accuracy: 0.7432\n",
            "Epoch 96/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7473 - val_loss: 0.5690 - val_accuracy: 0.7435\n",
            "Epoch 97/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7473 - val_loss: 0.5687 - val_accuracy: 0.7440\n",
            "Epoch 98/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5689 - val_accuracy: 0.7434\n",
            "Epoch 99/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5690 - val_accuracy: 0.7432\n",
            "Epoch 100/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5690 - val_accuracy: 0.7434\n",
            "Epoch 101/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 102/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 103/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 104/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 105/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5690 - val_accuracy: 0.7433\n",
            "Epoch 106/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5688 - val_accuracy: 0.7436\n",
            "Epoch 107/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7436\n",
            "Epoch 108/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7474 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 109/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 110/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7474 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 111/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 112/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 113/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 114/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 115/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 116/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7475 - val_loss: 0.5690 - val_accuracy: 0.7431\n",
            "Epoch 117/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 118/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 119/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 120/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7434\n",
            "Epoch 121/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5689 - val_accuracy: 0.7433\n",
            "Epoch 122/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 123/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 124/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 125/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 126/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 127/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 128/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7435\n",
            "Epoch 129/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7436\n",
            "Epoch 130/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7475 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 131/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 132/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 133/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 134/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 135/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 136/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7437\n",
            "Epoch 137/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5689 - val_accuracy: 0.7435\n",
            "Epoch 138/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7437\n",
            "Epoch 139/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7475 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 140/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 141/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 142/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5688 - val_accuracy: 0.7434\n",
            "Epoch 143/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 144/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 145/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 146/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7441\n",
            "Epoch 147/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 148/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7477 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 149/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 150/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7476 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 151/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7475 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 152/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7437\n",
            "Epoch 153/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 154/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 155/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5689 - val_accuracy: 0.7432\n",
            "Epoch 156/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 157/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 158/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 159/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5673 - accuracy: 0.7476 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 160/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 161/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 162/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 163/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7476 - val_loss: 0.5687 - val_accuracy: 0.7434\n",
            "Epoch 164/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 165/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 166/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 167/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5687 - val_accuracy: 0.7436\n",
            "Epoch 168/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7477 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 169/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5674 - accuracy: 0.7476 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 170/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 171/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7477 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 172/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 173/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 174/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 175/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7477 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 176/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 177/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 178/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7435\n",
            "Epoch 179/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 180/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 181/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 182/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 183/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 184/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 185/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 186/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 187/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 188/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 189/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 190/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 191/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5690 - val_accuracy: 0.7437\n",
            "Epoch 192/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 193/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7438\n",
            "Epoch 194/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7477 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 195/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 196/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 197/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 198/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 199/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 200/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 201/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7479 - val_loss: 0.5686 - val_accuracy: 0.7438\n",
            "Epoch 202/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 203/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 204/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 205/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 206/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 207/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 208/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 209/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 210/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 211/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7480 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 212/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5685 - val_accuracy: 0.7439\n",
            "Epoch 213/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 214/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 215/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 216/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 217/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 218/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7478 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 219/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7437\n",
            "Epoch 220/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 221/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7478 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 222/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 223/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 224/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 225/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 226/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 227/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 228/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 229/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7444\n",
            "Epoch 230/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7437\n",
            "Epoch 231/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 232/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 233/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 234/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 235/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 236/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7443\n",
            "Epoch 237/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5684 - val_accuracy: 0.7438\n",
            "Epoch 238/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 239/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 240/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 241/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 242/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 243/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 244/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 245/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 246/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7443\n",
            "Epoch 247/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 248/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5680 - val_accuracy: 0.7445\n",
            "Epoch 249/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.7440\n",
            "Epoch 250/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 251/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7439\n",
            "Epoch 252/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 253/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 254/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 255/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 256/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7439\n",
            "Epoch 257/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 258/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5670 - accuracy: 0.7479 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 259/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 260/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 261/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5668 - accuracy: 0.7478 - val_loss: 0.5685 - val_accuracy: 0.7442\n",
            "Epoch 262/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7442\n",
            "Epoch 263/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5670 - accuracy: 0.7481 - val_loss: 0.5684 - val_accuracy: 0.7443\n",
            "Epoch 264/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7441\n",
            "Epoch 265/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5680 - val_accuracy: 0.7443\n",
            "Epoch 266/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 267/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 268/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7445\n",
            "Epoch 269/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 270/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7479 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 271/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7444\n",
            "Epoch 272/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 273/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7440\n",
            "Epoch 274/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 275/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 276/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5670 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 277/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 278/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7444\n",
            "Epoch 279/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7483 - val_loss: 0.5682 - val_accuracy: 0.7442\n",
            "Epoch 280/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7481 - val_loss: 0.5681 - val_accuracy: 0.7441\n",
            "Epoch 281/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5686 - val_accuracy: 0.7439\n",
            "Epoch 282/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5684 - val_accuracy: 0.7442\n",
            "Epoch 283/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5681 - val_accuracy: 0.7442\n",
            "Epoch 284/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7482 - val_loss: 0.5684 - val_accuracy: 0.7440\n",
            "Epoch 285/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 286/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7480 - val_loss: 0.5681 - val_accuracy: 0.7446\n",
            "Epoch 287/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5686 - val_accuracy: 0.7441\n",
            "Epoch 288/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5684 - val_accuracy: 0.7441\n",
            "Epoch 289/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5666 - accuracy: 0.7482 - val_loss: 0.5682 - val_accuracy: 0.7441\n",
            "Epoch 290/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5668 - accuracy: 0.7480 - val_loss: 0.5680 - val_accuracy: 0.7444\n",
            "Epoch 291/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5683 - val_accuracy: 0.7440\n",
            "Epoch 292/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7481 - val_loss: 0.5685 - val_accuracy: 0.7440\n",
            "Epoch 293/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7482 - val_loss: 0.5683 - val_accuracy: 0.7441\n",
            "Epoch 294/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 295/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5667 - accuracy: 0.7482 - val_loss: 0.5682 - val_accuracy: 0.7444\n",
            "Epoch 296/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5666 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 297/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5671 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7444\n",
            "Epoch 298/300\n",
            "700/700 [==============================] - 2s 4ms/step - loss: 0.5669 - accuracy: 0.7481 - val_loss: 0.5681 - val_accuracy: 0.7443\n",
            "Epoch 299/300\n",
            "700/700 [==============================] - 2s 3ms/step - loss: 0.5667 - accuracy: 0.7480 - val_loss: 0.5682 - val_accuracy: 0.7443\n",
            "Epoch 300/300\n",
            "700/700 [==============================] - 3s 4ms/step - loss: 0.5666 - accuracy: 0.7481 - val_loss: 0.5682 - val_accuracy: 0.7442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAzV5iNswIRp",
        "outputId": "ef0ceb6e-879b-4a6e-ea3d-1da2c386528d"
      },
      "source": [
        "pipeline.score(X,y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.74742"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZqzkdg6C6A0",
        "outputId": "87843cd7-1ca0-4708-ab68-58c368c83879"
      },
      "source": [
        "preds = pipeline.predict_proba(test.iloc[:,1:101])\n",
        "preds"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900/900 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25104898, 0.748951  ],\n",
              "       [0.25104898, 0.748951  ],\n",
              "       [0.25104898, 0.748951  ],\n",
              "       ...,\n",
              "       [0.25129622, 0.7487038 ],\n",
              "       [0.25104898, 0.748951  ],\n",
              "       [0.25104898, 0.748951  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "twxC7aDPqNfu",
        "outputId": "cd2b876c-1a8c-403d-a37f-a4f28d139a4b"
      },
      "source": [
        "#Submission file creation\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kaggle_Nov/sample_submission.csv')\n",
        "submission[\"target\"] = preds[:,-1]\n",
        "submission.to_csv(\"/content/drive/MyDrive/Kaggle_Nov/submission1130_6.csv\", index=False)\n",
        "submission.head(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>600000</td>\n",
              "      <td>0.748951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>600001</td>\n",
              "      <td>0.748951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>600002</td>\n",
              "      <td>0.748951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>600003</td>\n",
              "      <td>0.249003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>600004</td>\n",
              "      <td>0.748951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>600005</td>\n",
              "      <td>0.248751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>600006</td>\n",
              "      <td>0.248751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>600007</td>\n",
              "      <td>0.455979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>600008</td>\n",
              "      <td>0.748951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>600009</td>\n",
              "      <td>0.248751</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    target\n",
              "0  600000  0.748951\n",
              "1  600001  0.748951\n",
              "2  600002  0.748951\n",
              "3  600003  0.249003\n",
              "4  600004  0.748951\n",
              "5  600005  0.248751\n",
              "6  600006  0.248751\n",
              "7  600007  0.455979\n",
              "8  600008  0.748951\n",
              "9  600009  0.248751"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}